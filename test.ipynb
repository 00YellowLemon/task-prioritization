{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1427/425629907.py:27: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  reflection_summary_chain = LLMChain(llm=llm, prompt=reflection_prompt_template, output_key=\"reflection_summary\")\n",
      "/tmp/ipykernel_1427/425629907.py:55: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
      "  reflection_summary_output = reflection_summary_chain.run(reflection=reflection_text)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Reflection:\n",
      "Question: What did you learn today?\n",
      "Answer: I learned about using Langchain with the Gemini model and environment variables.\n",
      "--------------------\n",
      "Question: What went well?\n",
      "Answer: Successfully integrated dotenv for API key management.\n",
      "--------------------\n",
      "Question: What could have gone better?\n",
      "Answer: Ensuring the .env file is properly configured.\n",
      "--------------------\n",
      "Question: What will you do differently next time?\n",
      "Answer: Explore more robust environment variable management strategies.\n",
      "--------------------\n",
      "\n",
      "One-Line Summary of Reflection:\n",
      "Today I learned to use Langchain with Gemini and environment variables, successfully integrating dotenv but needing to improve .env file configuration and explore more robust environment variable management.\n",
      "\n",
      "One-Line Summary of the Summary:\n",
      "Successfully integrated Langchain with Gemini and environment variables using dotenv, but needs improvement in .env file configuration and more robust environment variable management.\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the Gemini model\n",
    "# Assuming your Gemini API key is stored in an environment variable named GOOGLE_API_KEY\n",
    "gemini_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if not gemini_api_key:\n",
    "    raise ValueError(\"Please set the GOOGLE_API_KEY environment variable.\")\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", google_api_key=gemini_api_key)\n",
    "\n",
    "# Create a prompt template for summarizing the reflection\n",
    "reflection_prompt_template = PromptTemplate(\n",
    "    input_variables=[\"reflection\"],\n",
    "    template=\"\"\"Please provide a one-line summary of the following reflection:\n",
    "\n",
    "{reflection}\"\"\",\n",
    ")\n",
    "\n",
    "# Create a Langchain chain for summarizing the reflection\n",
    "reflection_summary_chain = LLMChain(llm=llm, prompt=reflection_prompt_template, output_key=\"reflection_summary\")\n",
    "\n",
    "# Create a prompt template for summarizing the reflection summary\n",
    "summary_summary_prompt_template = PromptTemplate(\n",
    "    input_variables=[\"reflection_summary\"],\n",
    "    template=\"\"\"Please provide a one-line summary of the following summary:\n",
    "\n",
    "{reflection_summary}\"\"\",\n",
    ")\n",
    "\n",
    "# Create a Langchain chain for summarizing the reflection summary\n",
    "summary_summary_chain = LLMChain(llm=llm, prompt=summary_summary_prompt_template, output_key=\"summary_summary\")\n",
    "\n",
    "def create_reflection_summary(reflection_data: dict) -> tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Takes a dictionary of reflection questions and answers and provides a one-line summary\n",
    "    of the reflection and a one-line summary of the generated summary.\n",
    "\n",
    "    Args:\n",
    "        reflection_data: A dictionary where keys are questions and values are answers.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing the one-line summary of the reflection and the one-line summary\n",
    "        of the generated summary.\n",
    "    \"\"\"\n",
    "    reflection_text = \"\\n\".join([f\"Question: {q}\\nAnswer: {a}\" for q, a in reflection_data.items()])\n",
    "\n",
    "    # Generate the one-line summary of the reflection\n",
    "    reflection_summary_output = reflection_summary_chain.run(reflection=reflection_text)\n",
    "    reflection_summary = reflection_summary_output.strip()\n",
    "\n",
    "    # Generate a one-line summary of the reflection summary\n",
    "    summary_summary_output = summary_summary_chain.run(reflection_summary=reflection_summary)\n",
    "    summary_summary = summary_summary_output.strip()\n",
    "\n",
    "    return reflection_summary, summary_summary\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    user_reflection = {\n",
    "        \"What did you learn today?\": \"I learned about using Langchain with the Gemini model and environment variables.\",\n",
    "        \"What went well?\": \"Successfully integrated dotenv for API key management.\",\n",
    "        \"What could have gone better?\": \"Ensuring the .env file is properly configured.\",\n",
    "        \"What will you do differently next time?\": \"Explore more robust environment variable management strategies.\",\n",
    "    }\n",
    "\n",
    "    reflection_summary, summary_summary = create_reflection_summary(user_reflection)\n",
    "\n",
    "    print(\"Original Reflection:\")\n",
    "    for question, answer in user_reflection.items():\n",
    "        print(f\"Question: {question}\")\n",
    "        print(f\"Answer: {answer}\")\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "    print(\"\\nOne-Line Summary of Reflection:\")\n",
    "    print(reflection_summary)\n",
    "\n",
    "    print(\"\\nOne-Line Summary of the Summary:\")\n",
    "    print(summary_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
